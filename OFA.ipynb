{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tally0818/OFA/blob/main/OFA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3zZWhfrUDnp2"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jnyGu4rGkhlA",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "!pip install calflops"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dcH6ppxUkiBZ"
      },
      "outputs": [],
      "source": [
        "from calflops import calculate_flops"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H1RWWVqhyla6"
      },
      "outputs": [],
      "source": [
        "def get_top_k_matrices(matrices, k):\n",
        "  norms = torch.tensor([matrices[i].abs().sum() for i in range(matrices.size(0))])\n",
        "  top_k_indices = norms.argsort(descending=True)[:k]\n",
        "  return [matrices[i] for i in top_k_indices]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YBS91FIyzSPj"
      },
      "outputs": [],
      "source": [
        "class ElasticConv(nn.Module):\n",
        "  def __init__(self, in_channels : int, out_channels : int, max_kernel_size : int = 7, device = 'cuda'):\n",
        "    super().__init__()\n",
        "    self.in_channels = in_channels\n",
        "    self.out_channels = out_channels\n",
        "    self.max_kernel_size = max_kernel_size\n",
        "    self.active_kernel_size = self.max_kernel_size\n",
        "    self.device = device\n",
        "    self.stride = 1\n",
        "    self.p1_kernels = nn.Parameter(torch.randn(self.out_channels,\n",
        "                                            self.in_channels,\n",
        "                                            1,\n",
        "                                            1)).to(self.device)\n",
        "\n",
        "    self.dep_kernels = nn.Parameter(torch.randn(self.out_channels,\n",
        "                                            1,\n",
        "                                            self.max_kernel_size,\n",
        "                                            self.max_kernel_size)).to(self.device)\n",
        "\n",
        "    self.p2_kernels = nn.Parameter(torch.randn(self.out_channels,\n",
        "                                            self.out_channels,\n",
        "                                            1,\n",
        "                                            1)).to(self.device)\n",
        "\n",
        "    self.active_dep_kernels = self.dep_kernels\n",
        "    self.active_p1_kernels = self.p1_kernels\n",
        "    self.active_p2_kernels = self.p2_kernels\n",
        "    self.ReLU6 = nn.ReLU6()\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = F.conv2d(x, self.active_p1_kernels, stride=self.stride)\n",
        "    x = self.ReLU6(x)\n",
        "    x = F.conv2d(x, self.active_dep_kernels,\n",
        "                 stride=1,\n",
        "                 padding = self.active_kernel_size // 2,\n",
        "                 groups = self.out_channels)\n",
        "    x = F.conv2d(x, self.active_p2_kernels, stride=1)\n",
        "    x = self.ReLU6(x)\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dSy8FhtiNyVW"
      },
      "outputs": [],
      "source": [
        "class Conv(nn.Module):\n",
        "  def __init__(self, in_channels : int, out_channels : int, p1_kernels, dep_kernels, p2_kernels, kernel_size : int = 3, stride : int = 1, padding : int = 1):\n",
        "    super().__init__()\n",
        "    self.in_channels = in_channels\n",
        "    self.out_channels = out_channels\n",
        "    self.p1_kernels = p1_kernels\n",
        "    self.dep_kernels = dep_kernels\n",
        "    self.p2_kernels = p2_kernels\n",
        "    self.kernel_size = kernel_size\n",
        "    self.stride = stride\n",
        "    self.padding = padding\n",
        "    self.ReLU6 = nn.ReLU6()\n",
        "    self.point_conv1 = nn.Conv2d(self.in_channels, self.out_channels, kernel_size=1, stride=self.stride)\n",
        "    self.point_conv1.weight.data = self.p1_kernels\n",
        "    self.dep_conv = nn.Conv2d(self.out_channels, self.out_channels, kernel_size = self.kernel_size,\n",
        "                              padding = self.kernel_size // 2, groups = self.out_channels)\n",
        "    self.dep_conv.weight.data = self.dep_kernels\n",
        "    self.point_conv2 = nn.Conv2d(self.out_channels, self.out_channels, kernel_size=1, stride=1)\n",
        "    self.point_conv2.weight.data = self.p2_kernels\n",
        "  def forward(self, x):\n",
        "    x = self.point_conv1(x)\n",
        "    x = self.ReLU6(x)\n",
        "    x = self.dep_conv(x)\n",
        "    x = self.point_conv2(x)\n",
        "    x = self.ReLU6(x)\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fKb6GTQYQAzn"
      },
      "outputs": [],
      "source": [
        "def get_fixed_Conv(ElasticConv : ElasticConv)->Conv:\n",
        "  p1_kernels = ElasticConv.active_p1_kernels.clone()\n",
        "  dep_kernels = ElasticConv.active_dep_kernels.clone()\n",
        "  p2_kernels = ElasticConv.active_p2_kernels.clone()\n",
        "  return Conv(ElasticConv.in_channels,\n",
        "              ElasticConv.out_channels,\n",
        "              p1_kernels,\n",
        "              dep_kernels,\n",
        "              p2_kernels,\n",
        "              ElasticConv.active_kernel_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O0_6X5Erlyhu"
      },
      "outputs": [],
      "source": [
        "class ElasticSqueezeAndExcite(nn.Module):\n",
        "  def __init__(self, channels : int, reduction : int = 4, device = 'cuda'):\n",
        "    super().__init__()\n",
        "    self.channels = channels\n",
        "    self.reduction = reduction\n",
        "    self.device = device\n",
        "    self.reduced_channels = self.channels // self.reduction\n",
        "    self.fc1_weights = nn.Parameter(torch.randn(self.reduced_channels, self.channels, 1, 1)).to(device)\n",
        "    self.fc2_weights = nn.Parameter(torch.randn(self.channels, self.reduced_channels, 1, 1)).to(device)\n",
        "    self.active_fc1_weights = self.fc1_weights\n",
        "    self.active_fc2_weights = self.fc2_weights\n",
        "    self.active_channels = self.channels\n",
        "    self.active_reduced_channels = self.reduced_channels\n",
        "\n",
        "  def _process_kernels(self, weights, out_ch_count):\n",
        "    '''\n",
        "    weights : (channels, in_channels, s, s) -> (out_ch_count, in_channels, s, s) or\n",
        "    weights : (channels, s, s) -> (out_ch_count, s, s)\n",
        "    '''\n",
        "    top_weights = get_top_k_matrices(weights, out_ch_count)\n",
        "    return torch.stack(top_weights).to(self.device)\n",
        "\n",
        "  def shrink(self, elastic_channels):\n",
        "    '''\n",
        "    active_fc1_weights : (reduced_channels, channels, 1, 1) -> (elastic_channels//4, elastic_channels, 1, 1)\n",
        "    active_fc2_weights : (channels, reduced_channels, 1, 1) -> (elastic_channels, elastic_channels//4, 1, 1)\n",
        "    '''\n",
        "    if elastic_channels == self.active_channels:\n",
        "      return\n",
        "\n",
        "    self.active_channels = elastic_channels\n",
        "    self.active_reduced_channels = self.active_channels // self.reduction\n",
        "\n",
        "    fc1_in_weights = self._process_kernels(self.fc1_weights, self.active_reduced_channels)\n",
        "    processed_fc1_weights = []\n",
        "    for ch_weight in fc1_in_weights:\n",
        "      reduced_top = get_top_k_matrices(ch_weight, self.active_channels)\n",
        "      processed_fc1_weights.append(torch.stack(reduced_top))\n",
        "\n",
        "    self.active_fc1_weights = torch.stack(processed_fc1_weights).to(self.device)\n",
        "\n",
        "    fc2_in_weights = self._process_kernels(self.fc2_weights, self.active_channels)\n",
        "    processed_fc2_weights = []\n",
        "    for ch_weight in fc2_in_weights:\n",
        "      out_top = get_top_k_matrices(ch_weight, self.active_reduced_channels)\n",
        "      processed_fc2_weights.append(torch.stack(out_top))\n",
        "\n",
        "    self.active_fc2_weights = torch.stack(processed_fc2_weights).to(self.device)\n",
        "\n",
        "  def forward(self, x):\n",
        "    scale = F.adaptive_avg_pool2d(x, 1)\n",
        "    scale = F.conv2d(scale, self.active_fc1_weights)\n",
        "    scale = F.relu(scale)\n",
        "    scale = F.conv2d(scale, self.active_fc2_weights)\n",
        "    scale = F.hardsigmoid(scale)\n",
        "    return x * scale"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q9Ro8cTpoXhV"
      },
      "outputs": [],
      "source": [
        "class SqueezeAndExcite(nn.Module):\n",
        "  def __init__(self, channels : int, reduction : int = 4, fc1_weights = None, fc2_weights = None):\n",
        "    super().__init__()\n",
        "    self.channels = channels\n",
        "    self.reduction = reduction\n",
        "    self.reduced_channels = max(1, self.channels // self.reduction)\n",
        "    self.fc1 = nn.Conv2d(self.channels, self.reduced_channels, 1, bias=False)\n",
        "    self.fc2 = nn.Conv2d(self.reduced_channels, self.channels, 1, bias=False)\n",
        "    self.fc1.weight.data = fc1_weights\n",
        "    self.fc2.weight.data = fc2_weights\n",
        "\n",
        "  def forward(self, x):\n",
        "    scale = F.adaptive_avg_pool2d(x, 1)\n",
        "    scale = self.fc1(scale)\n",
        "    scale = F.relu(scale)\n",
        "    scale = self.fc2(scale)\n",
        "    scale = F.hardsigmoid(scale)\n",
        "    return x * scale"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R0OcmhpXoV1U"
      },
      "outputs": [],
      "source": [
        "def get_fixed_SqueezeAndExcite(ElasticSqueezeAndExcite : ElasticSqueezeAndExcite) -> SqueezeAndExcite:\n",
        "  return SqueezeAndExcite(\n",
        "      ElasticSqueezeAndExcite.active_channels,\n",
        "      ElasticSqueezeAndExcite.reduction,\n",
        "      ElasticSqueezeAndExcite.active_fc1_weights,\n",
        "      ElasticSqueezeAndExcite.active_fc2_weights\n",
        "  )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KjE38HkIq16R"
      },
      "outputs": [],
      "source": [
        "class ElasticMBblock(nn.Module): #layer\n",
        "  def __init__(self, in_channels : int, max_width : int = 6, max_kernel_size : int = 7, device = 'cuda'):\n",
        "    super().__init__()\n",
        "    self.in_channels = in_channels\n",
        "    self.max_width = max_width\n",
        "    self.max_kernel_size = max_kernel_size\n",
        "    self.device = device\n",
        "    self.out_channels = in_channels * self.max_width\n",
        "    self.transfrom_matrix_725 = nn.Parameter(torch.randn(self.max_kernel_size**2, 25)) # transforming max_size * max_size kernel 2 5*5 kernel\n",
        "    self.transfrom_matrix_523 = nn.Parameter(torch.randn(25, 9)) # transforming 5*5 kernel 2 3*3 kernel\n",
        "    self.dep_conv = ElasticConv(self.in_channels, self.out_channels, self.max_kernel_size, self.device)\n",
        "    self.se = ElasticSqueezeAndExcite(self.out_channels, 4, self.device)\n",
        "    self.active_kernel_size = self.max_kernel_size\n",
        "    self.active_width = self.max_width\n",
        "\n",
        "  def get_transform_matrix(self, elastic_kernel_size : int):\n",
        "    if elastic_kernel_size == self.max_kernel_size:\n",
        "      return torch.eye(self.max_kernel_size**2).to(self.device)\n",
        "    elif elastic_kernel_size == 5:\n",
        "      return self.transfrom_matrix_725\n",
        "    elif elastic_kernel_size == 3:\n",
        "      return torch.matmul(self.transfrom_matrix_725, self.transfrom_matrix_523).to(self.device)\n",
        "    else:\n",
        "      raise ValueError(\"Unsupported kernel size\")\n",
        "\n",
        "  def _process_kernels(self, kernels, in_ch_count, transform_matrix=None):\n",
        "    top_channels = get_top_k_matrices(kernels, self.out_channels)\n",
        "    results = []\n",
        "    for channel in top_channels:\n",
        "      if transform_matrix is not None: # For depthwise kernels that need transformation\n",
        "        transformed_channels = []\n",
        "        for kernel in channel:\n",
        "          transformed = torch.matmul(kernel.view(1, -1), transform_matrix).view(self.active_kernel_size, self.active_kernel_size)\n",
        "          transformed_channels.append(transformed)\n",
        "        results.append(torch.stack(transformed_channels))\n",
        "      else: # For pointwise kernels\n",
        "        in_channels_top = get_top_k_matrices(channel, in_ch_count)\n",
        "        results.append(torch.stack(in_channels_top))\n",
        "\n",
        "    return torch.stack(results).to(self.device)\n",
        "\n",
        "  def shrink(self, elastic_kernel_size: int, elastic_width: int):\n",
        "    self.active_kernel_size = elastic_kernel_size\n",
        "    self.active_width = elastic_width\n",
        "    self.dep_conv.active_kernel_size = elastic_kernel_size\n",
        "    self.out_channels = self.in_channels * elastic_width\n",
        "    self.dep_conv.out_channels = self.out_channels\n",
        "    self.se.shrink(self.out_channels)\n",
        "    transform_matrix = self.get_transform_matrix(elastic_kernel_size)\n",
        "    self.dep_conv.active_p1_kernels = self._process_kernels(self.dep_conv.p1_kernels, self.in_channels)\n",
        "    self.dep_conv.active_dep_kernels = self._process_kernels(self.dep_conv.dep_kernels, None, transform_matrix)\n",
        "    self.dep_conv.active_p2_kernels = self._process_kernels(self.dep_conv.p2_kernels, self.out_channels)\n",
        "\n",
        "\n",
        "  def forward(self, x):\n",
        "    x_copy = x.clone()\n",
        "    x = self.dep_conv(x)\n",
        "    x = self.se(x)\n",
        "    if self.in_channels == self.out_channels:\n",
        "      x += x_copy # optional residual connection\n",
        "    return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PZiFPS1-L0fA"
      },
      "outputs": [],
      "source": [
        "class MBblock(nn.Module): #layer\n",
        "  def __init__(self, in_channels : int, out_channels : int, conv : Conv, se : SqueezeAndExcite, device = 'cuda'):\n",
        "    super().__init__()\n",
        "    self.in_channels = in_channels\n",
        "    self.out_channels = out_channels\n",
        "    self.conv = conv\n",
        "    self.se = se\n",
        "    self.device = device\n",
        "\n",
        "  def forward(self, x):\n",
        "    x_copy = x.clone()\n",
        "    x = self.conv(x)\n",
        "    x = self.se(x)\n",
        "    if self.in_channels == self.out_channels:\n",
        "      x += x_copy # optional residual connection\n",
        "    return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nTA8cfjRQZMT"
      },
      "outputs": [],
      "source": [
        "def get_fixed_MBblock(ElasticMBblock : ElasticMBblock)->MBblock:\n",
        "  conv = get_fixed_Conv(ElasticMBblock.dep_conv)\n",
        "  se = get_fixed_SqueezeAndExcite(ElasticMBblock.se)\n",
        "  return MBblock(ElasticMBblock.in_channels, ElasticMBblock.out_channels, conv, se, ElasticMBblock.device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KeY9yUcyk4NV"
      },
      "outputs": [],
      "source": [
        "class ElasticUnit(nn.Module):\n",
        "  def __init__(self,\n",
        "               in_channels : int,\n",
        "               max_width : int = 6,\n",
        "               max_kernel_size : int = 7,\n",
        "               max_depth : int = 4,\n",
        "               device = 'cuda'):\n",
        "    super().__init__()\n",
        "    self.in_channels = in_channels\n",
        "    self.max_width = max_width\n",
        "    self.max_kernel_size = max_kernel_size\n",
        "    self.max_depth = max_depth\n",
        "    self.device = device\n",
        "    self.out_channels = 0\n",
        "    self.layers = nn.ModuleList()\n",
        "    self._set_layers()\n",
        "    self.active_layers = self.layers\n",
        "\n",
        "  def _set_layers(self):\n",
        "    tmp_channels = self.in_channels\n",
        "    for i in range(self.max_depth):\n",
        "      layer = ElasticMBblock(tmp_channels, self.max_width, self.max_kernel_size, self.device)\n",
        "      self.layers.append(layer)\n",
        "      tmp_channels = layer.out_channels\n",
        "    self.out_channels = tmp_channels\n",
        "\n",
        "  def forward(self, x):\n",
        "    for layer in self.active_layers:\n",
        "      x = layer(x)\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LJMeI-emMR2v"
      },
      "outputs": [],
      "source": [
        "class Unit(nn.Module):\n",
        "  def __init__(self, in_channels : int, out_channels : int, layers : nn.ModuleList):\n",
        "    super().__init__()\n",
        "    self.in_channels = in_channels\n",
        "    self.out_channels = out_channels\n",
        "    self.layers = layers\n",
        "\n",
        "  def forward(self, x):\n",
        "    for layer in self.layers:\n",
        "      x = layer(x)\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RH6RfPGgQv7D"
      },
      "outputs": [],
      "source": [
        "def get_fixed_Unit(ElasticUnit : ElasticUnit)->Unit:\n",
        "  layers = nn.ModuleList()\n",
        "  for layer in ElasticUnit.active_layers:\n",
        "    layers.append(get_fixed_MBblock(layer))\n",
        "  return Unit(ElasticUnit.in_channels, ElasticUnit.out_channels, layers)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VQ9qdxffq13w"
      },
      "outputs": [],
      "source": [
        "class OFAnet(nn.Module):\n",
        "  def __init__(self,\n",
        "               num_units : int = 5,\n",
        "               in_channels : int = 3,\n",
        "               num_classes : int = 1000,\n",
        "               max_depth : int = 4,\n",
        "               max_width : int = 6,\n",
        "               max_kernel_size : int = 7,\n",
        "               device = 'cuda',\n",
        "               init_channels : int = 8,\n",
        "               fixed_reduction : bool = False\n",
        "               ):\n",
        "    super().__init__()\n",
        "    self.num_units = num_units\n",
        "    self.in_channels = in_channels\n",
        "    self.num_classes = num_classes\n",
        "    self.max_depth = max_depth\n",
        "    self.max_width = max_width\n",
        "    self.max_kernel_size = max_kernel_size\n",
        "    self.device = device\n",
        "    self.init_channels = init_channels\n",
        "    self.active_channels = self.init_channels\n",
        "    self.fixed_reduction = fixed_reduction\n",
        "    self.stem = nn.Sequential(nn.Conv2d(self.in_channels, self.init_channels, kernel_size=3, stride=2, padding=1),\n",
        "                              ElasticMBblock(in_channels = self.init_channels, max_width = 1)\n",
        "                              )\n",
        "\n",
        "    self.units = nn.ModuleList()\n",
        "\n",
        "    self._set_units()\n",
        "    self.final_layer = ElasticMBblock(in_channels = self.active_channels,\n",
        "                                      max_width = self.max_width,\n",
        "                                      max_kernel_size = self.max_kernel_size)\n",
        "    self.global_pool = nn.AdaptiveAvgPool2d(1)\n",
        "    self.classifier = nn.Linear(self.max_width * self.active_channels, num_classes)\n",
        "\n",
        "  def _set_units(self):\n",
        "    for i in range(self.num_units):\n",
        "      unit = ElasticUnit(self.active_channels, self.max_width, self.max_kernel_size, self.max_depth, self.device)\n",
        "      if self.fixed_reduction:\n",
        "        unit.layers[0].dep_conv.stride = 2\n",
        "      self.units.append(unit)\n",
        "      self.active_channels = unit.out_channels\n",
        "\n",
        "  def _process_layer_for_shrinking(self, layer, active_channels, config):\n",
        "    elastic_kernel_size = config[\"k\"]\n",
        "    elastic_width = config[\"w\"]\n",
        "    layer.in_channels = active_channels\n",
        "    layer.out_channels = layer.in_channels * elastic_width\n",
        "    layer.shrink(elastic_kernel_size, elastic_width)\n",
        "    return layer.out_channels\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.stem(x)\n",
        "    for unit in self.units:\n",
        "      x = unit(x)\n",
        "    x = self.final_layer(x)\n",
        "    x = self.global_pool(x)\n",
        "    x = x.view(x.size(0), -1)\n",
        "    x = self.classifier(x)\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U2Sh2QtjMcc-"
      },
      "outputs": [],
      "source": [
        "class Subnet(nn.Module):\n",
        "  def __init__(self, stem, units, final_layer, global_pool, classifier):\n",
        "    super().__init__()\n",
        "    self.in_channels = stem[0].in_channels\n",
        "    self.stem = stem\n",
        "    self.units = units\n",
        "    self.final_layer = final_layer\n",
        "    self.global_pool = global_pool\n",
        "    self.classifier = classifier\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.stem(x)\n",
        "    for unit in self.units:\n",
        "      x = unit(x)\n",
        "    x = self.final_layer(x)\n",
        "    x = self.global_pool(x)\n",
        "    x = x.view(x.size(0), -1)\n",
        "    x = self.classifier(x)\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1WUy_Pw7Rnwd"
      },
      "outputs": [],
      "source": [
        "def get_fixed_Subnet(OFAnet: OFAnet) -> Subnet:\n",
        "    stem_conv = OFAnet.stem[0]\n",
        "    elastic_block = OFAnet.stem[1]\n",
        "    fixed_stem_block = get_fixed_MBblock(elastic_block)\n",
        "    fixed_stem = nn.Sequential(stem_conv, fixed_stem_block)\n",
        "    fixed_units = nn.ModuleList()\n",
        "\n",
        "    for unit in OFAnet.units:\n",
        "        fixed_unit = get_fixed_Unit(unit)\n",
        "        fixed_units.append(fixed_unit)\n",
        "    fixed_final_layer = get_fixed_MBblock(OFAnet.final_layer)\n",
        "    global_pool = OFAnet.global_pool\n",
        "    classifier = OFAnet.classifier\n",
        "\n",
        "    return Subnet(\n",
        "        stem=fixed_stem,\n",
        "        units=fixed_units,\n",
        "        final_layer=fixed_final_layer,\n",
        "        global_pool=global_pool,\n",
        "        classifier=classifier\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xui1Gkhiq11n"
      },
      "outputs": [],
      "source": [
        "def ProgressiveShrinking(supernet: OFAnet, configs: list[list[dict]]) -> Subnet:\n",
        "  # shrink depth via keeping first D layers\n",
        "  for unit_idx, unit in enumerate(supernet.units):\n",
        "    unit_config = configs[unit_idx]\n",
        "    elastic_depth = len(unit_config)\n",
        "    unit.active_layers = unit.layers[:elastic_depth]\n",
        "\n",
        "  # shrink kernel size via transformation matrix & shrink width via L1 norm of kernels\n",
        "  active_channels = supernet.init_channels\n",
        "  for unit_idx, unit in enumerate(supernet.units):\n",
        "    unit.in_channels = active_channels\n",
        "    for layer_idx, layer in enumerate(unit.active_layers):\n",
        "      layer_config = configs[unit_idx][layer_idx]\n",
        "      elastic_kernel_size = layer_config[\"k\"]\n",
        "      elastic_width = layer_config[\"w\"]\n",
        "      if not (layer.active_kernel_size == elastic_kernel_size and\n",
        "              layer.active_width == elastic_width and\n",
        "              layer.in_channels == active_channels):\n",
        "        layer.in_channels = active_channels\n",
        "        layer.shrink(elastic_kernel_size, elastic_width)\n",
        "      active_channels = layer.out_channels\n",
        "    unit.out_channels = active_channels\n",
        "\n",
        "  # Handle final layer\n",
        "  supernet.final_layer.in_channels = active_channels\n",
        "  final_p1_kernels = supernet.final_layer.dep_conv.p1_kernels.clone()\n",
        "  supernet.final_layer.dep_conv.active_p1_kernels = supernet.final_layer._process_kernels(final_p1_kernels, active_channels)\n",
        "\n",
        "  # get Subnet\n",
        "  subnet = get_fixed_Subnet(supernet)\n",
        "  return subnet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_y-Ma_Edq1zF"
      },
      "outputs": [],
      "source": [
        "def get_simple_configs(num_units, k, d, w):\n",
        "  return [[{\"k\":k, \"w\":w} for layer in range(d)] for unit in range(num_units)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zWCzZcARU-uQ"
      },
      "outputs": [],
      "source": [
        "def iterate_config_space(num_units, config_space : list[list[int]]):\n",
        "  configs = []\n",
        "  for k in config_space[0]:\n",
        "    for d in config_space[1]:\n",
        "      for w in config_space[2]:\n",
        "         configs.append(get_simple_configs(num_units, k, d, w))\n",
        "  return configs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7lTkD9c8Bj1o"
      },
      "outputs": [],
      "source": [
        "def sample_config(num_units, config_space : list[list[int]], fixed_dims : list = []):\n",
        "  d = np.random.choice(config_space[1]) if \"d\" not in fixed_dims else config_space[1][-1]\n",
        "  config = []\n",
        "  for unit in range(num_units):\n",
        "    unit_config = []\n",
        "    for layer in range(d):\n",
        "      k = np.random.choice(config_space[0]) if \"k\" not in fixed_dims else config_space[0][-1]\n",
        "      w = np.random.choice(config_space[2]) if \"w\" not in fixed_dims else config_space[2][-1]\n",
        "      unit_config.append({\"k\":k, \"w\":w})\n",
        "    config.append(unit_config)\n",
        "  return config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xf_yhlDYaTE-"
      },
      "outputs": [],
      "source": [
        "def train_OFAnet(supernet, config_space, epochs, dataloader, criterion, optimizers, schedulers, device):\n",
        "  fixed_dims = [\"d\", \"w\"]\n",
        "  supernet.train()\n",
        "  for stage in range(3):\n",
        "    optimizer = optimizers[stage]\n",
        "    scheduler = schedulers[stage]\n",
        "    for epoch in range(1, epochs + 1):\n",
        "      config = sample_config(supernet.num_units, config_space, fixed_dims)\n",
        "      subnet = ProgressiveShrinking(supernet, config)\n",
        "      subnet.to(device)\n",
        "      loss = train_one_epoch(subnet, train_loader, criterion, optimizer, device)\n",
        "      scheduler.step()\n",
        "      if epoch % 5 == 0:\n",
        "        print(f\"Stage {stage + 1}, Epoch [{epoch}/{epochs}], Loss: {loss:.4f}\")\n",
        "    fixed_dims = fixed_dims[:-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xL-whjy5wrtU"
      },
      "outputs": [],
      "source": [
        "def train_one_epoch(model, dataloader, criterion, optimizer, device):\n",
        "  model.train()\n",
        "  running_loss = 0.0\n",
        "  for images, targets in dataloader:\n",
        "    images, targets = images.to(device), targets.to(device)\n",
        "    optimizer.zero_grad()\n",
        "    outputs = model(images)\n",
        "    loss = criterion(outputs, targets)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    running_loss += loss.item() * images.size(0)\n",
        "  return running_loss / len(dataloader.dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wjFm1s71vH4R"
      },
      "outputs": [],
      "source": [
        "def evaluate(model, dataloader, device):\n",
        "  model.eval()\n",
        "  correct = 0\n",
        "  total = 0\n",
        "  with torch.no_grad():\n",
        "    for images, targets in dataloader:\n",
        "      images, targets = images.to(device), targets.to(device)\n",
        "      outputs = model(images)\n",
        "      _, preds = torch.max(outputs, 1)\n",
        "      correct += (preds == targets).sum().item()\n",
        "      total += targets.size(0)\n",
        "  return correct / total"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "it_bYX33vJGY"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dk6zBDCDvJD8"
      },
      "outputs": [],
      "source": [
        "transform_train = transforms.Compose([\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.4914, 0.4822, 0.4465),\n",
        "                     (0.2023, 0.1994, 0.2010))\n",
        "    ])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fkaPPlOnvJBY"
      },
      "outputs": [],
      "source": [
        "transform_test = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.4914, 0.4822, 0.4465),\n",
        "                     (0.2023, 0.1994, 0.2010))\n",
        "    ])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1HtlBheBvL6s",
        "outputId": "fda58098-5e89-4c67-eb85-9183367ae2de"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170M/170M [00:13<00:00, 13.1MB/s]\n"
          ]
        }
      ],
      "source": [
        "train_dataset = torchvision.datasets.CIFAR10(root=\"./data\", train=True, download=True, transform=transform_train)\n",
        "test_dataset = torchvision.datasets.CIFAR10(root=\"./data\", train=False, download=True, transform=transform_test)\n",
        "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True, num_workers=4)\n",
        "test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False, num_workers=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "chZejPV1vL4A",
        "outputId": "fb20dff6-d3c5-425b-f8d1-8c412bce37de"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OFAnet(\n",
              "  (stem): Sequential(\n",
              "    (0): Conv2d(3, 8, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
              "    (1): ElasticMBblock(\n",
              "      (dep_conv): ElasticConv(\n",
              "        (ReLU6): ReLU6()\n",
              "      )\n",
              "      (se): ElasticSqueezeAndExcite()\n",
              "    )\n",
              "  )\n",
              "  (units): ModuleList(\n",
              "    (0): ElasticUnit(\n",
              "      (layers): ModuleList(\n",
              "        (0-2): 3 x ElasticMBblock(\n",
              "          (dep_conv): ElasticConv(\n",
              "            (ReLU6): ReLU6()\n",
              "          )\n",
              "          (se): ElasticSqueezeAndExcite()\n",
              "        )\n",
              "      )\n",
              "      (active_layers): ModuleList(\n",
              "        (0-2): 3 x ElasticMBblock(\n",
              "          (dep_conv): ElasticConv(\n",
              "            (ReLU6): ReLU6()\n",
              "          )\n",
              "          (se): ElasticSqueezeAndExcite()\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (final_layer): ElasticMBblock(\n",
              "    (dep_conv): ElasticConv(\n",
              "      (ReLU6): ReLU6()\n",
              "    )\n",
              "    (se): ElasticSqueezeAndExcite()\n",
              "  )\n",
              "  (global_pool): AdaptiveAvgPool2d(output_size=1)\n",
              "  (classifier): Linear(in_features=2048, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "supernet = OFAnet(num_units=1,\n",
        "                  in_channels=3,\n",
        "                  num_classes=10,\n",
        "                  max_depth=3,\n",
        "                  max_width=4,\n",
        "                  max_kernel_size=7,\n",
        "                  fixed_reduction = True)\n",
        "supernet.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LjoutlxsWIiN"
      },
      "outputs": [],
      "source": [
        "config_space = [[5, 7], # k\n",
        "                [2, 3], # d\n",
        "                [2, 4]  # w\n",
        "                 ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qZ2AB72biBDo",
        "outputId": "7d0fcc03-c960-4244-e1fb-ab7769cbaf7f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [10/180], Loss: 24300.6246\n",
            "Epoch [20/180], Loss: 27081.0991\n",
            "Epoch [30/180], Loss: 25827.4613\n",
            "Epoch [40/180], Loss: 25561.2965\n",
            "Epoch [50/180], Loss: 23562.3627\n",
            "Epoch [60/180], Loss: 20719.7780\n",
            "Epoch [70/180], Loss: 17261.6188\n",
            "Epoch [80/180], Loss: 14938.7788\n",
            "Epoch [90/180], Loss: 12885.2181\n",
            "Epoch [100/180], Loss: 9825.3774\n",
            "Epoch [110/180], Loss: 8000.0122\n",
            "Epoch [120/180], Loss: 6313.3398\n",
            "Epoch [130/180], Loss: 4094.1782\n",
            "Epoch [140/180], Loss: 2416.6540\n",
            "Epoch [150/180], Loss: 1239.7816\n",
            "Epoch [160/180], Loss: 456.5941\n",
            "Epoch [170/180], Loss: 76.6134\n",
            "Epoch [180/180], Loss: 54.8479\n",
            "done training supernet\n",
            "supernet accuracy: 0.2149\n"
          ]
        }
      ],
      "source": [
        "# Now let's train the OFA network\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "epochs = 180\n",
        "\n",
        "optimizer = torch.optim.SGD(supernet.parameters(), lr=2.6, momentum=0.9, weight_decay=3e-5)\n",
        "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs)\n",
        "for epoch in range(1, epochs + 1):\n",
        "  loss = train_one_epoch(supernet, train_loader, criterion, optimizer, device)\n",
        "  scheduler.step()\n",
        "  if epoch % 10 == 0:\n",
        "    print(f\"Epoch [{epoch}/{epochs}], Loss: {loss:.4f}\")\n",
        "print(\"done training supernet\")\n",
        "acc = evaluate(supernet, test_loader, device)\n",
        "print(\"supernet accuracy:\",acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "so4Hd8rH02AK",
        "outputId": "9933f25b-5ae2-41bc-a948-4c922c7ec424"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stage 1, Epoch [5/25], Loss: 253.8057\n",
            "Stage 1, Epoch [10/25], Loss: 468.5583\n",
            "Stage 1, Epoch [15/25], Loss: 468.4309\n",
            "Stage 1, Epoch [20/25], Loss: 457.4867\n",
            "Stage 1, Epoch [25/25], Loss: 285.8737\n",
            "Stage 2, Epoch [5/25], Loss: 647.3961\n",
            "Stage 2, Epoch [10/25], Loss: 649.8146\n",
            "Stage 2, Epoch [15/25], Loss: 266.9540\n",
            "Stage 2, Epoch [20/25], Loss: 59.0908\n",
            "Stage 2, Epoch [25/25], Loss: 66.2991\n",
            "Stage 3, Epoch [5/25], Loss: 939.9427\n",
            "Stage 3, Epoch [10/25], Loss: 513.8098\n",
            "Stage 3, Epoch [15/25], Loss: 311.1151\n",
            "Stage 3, Epoch [20/25], Loss: 54.9380\n",
            "Stage 3, Epoch [25/25], Loss: 69.2655\n"
          ]
        }
      ],
      "source": [
        "ft_epochs = 25\n",
        "optimizers = [torch.optim.SGD([param for name, param in supernet.named_parameters() if \"matrix\" in name], lr=0.96, momentum=0.9, weight_decay=3e-5),\n",
        "              torch.optim.SGD(supernet.parameters(), lr=0.08, momentum=0.9, weight_decay=3e-5),\n",
        "              torch.optim.SGD(supernet.parameters(), lr=0.08, momentum=0.9, weight_decay=3e-5)]\n",
        "schedulers = [torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=ft_epochs) for optimizer in optimizers]\n",
        "\n",
        "train_OFAnet(supernet, config_space, ft_epochs, train_loader, criterion, optimizers, schedulers, device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4EGv05tx04yx"
      },
      "outputs": [],
      "source": [
        "torch.save(supernet.state_dict(), 'supernet.pt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "id": "3hPKe4wRBnue",
        "outputId": "7b28c688-cbce-4a37-d497-41250adfff4e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\nsupernet = OFAnet(num_units=1,\\n                  in_channels=3,\\n                  num_classes=10,\\n                  max_depth=3,\\n                  max_width=4,\\n                  max_kernel_size=7,\\n                  fixed_reduction = True)\\nsupernet.load_state_dict(torch.load('supernet.pt'))\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "source": [
        "'''\n",
        "supernet = OFAnet(num_units=1,\n",
        "                  in_channels=3,\n",
        "                  num_classes=10,\n",
        "                  max_depth=3,\n",
        "                  max_width=4,\n",
        "                  max_kernel_size=7,\n",
        "                  fixed_reduction = True)\n",
        "supernet.load_state_dict(torch.load('supernet.pt'))\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RW9uI3_YlENo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5cdd455d-4d2a-4538-b8ee-eb064f3d5905"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(k, d, w): (5, 2, 2)\n",
            "\n",
            "------------------------------------- Calculate Flops Results -------------------------------------\n",
            "Notations:\n",
            "number of parameters (Params), number of multiply-accumulate operations(MACs),\n",
            "number of floating-point operations (FLOPs), floating-point operations per second (FLOPS),\n",
            "fwd FLOPs (model forward propagation FLOPs), bwd FLOPs (model backward propagation FLOPs),\n",
            "default model backpropagation takes 2.00 times as much computation as forward propagation.\n",
            "\n",
            "Total Training Params:                                                  27.96 K \n",
            "fwd MACs:                                                               281.759 MMACs\n",
            "fwd FLOPs:                                                              563.791 MFLOPS\n",
            "fwd+bwd MACs:                                                           845.277 MMACs\n",
            "fwd+bwd FLOPs:                                                          1.6914 GFLOPS\n",
            "---------------------------------------------------------------------------------------------------\n",
            "Subnet FLOPs:563.791 MFLOPS   MACs:281.759 MMACs   Params:27.964 K \n",
            "\n",
            "acc before fine-tuning: 0.1003\n",
            "acc after fine-tuning: 0.1551\n",
            "(k, d, w): (5, 2, 4)\n",
            "\n",
            "------------------------------------- Calculate Flops Results -------------------------------------\n",
            "Notations:\n",
            "number of parameters (Params), number of multiply-accumulate operations(MACs),\n",
            "number of floating-point operations (FLOPs), floating-point operations per second (FLOPS),\n",
            "fwd FLOPs (model forward propagation FLOPs), bwd FLOPs (model backward propagation FLOPs),\n",
            "default model backpropagation takes 2.00 times as much computation as forward propagation.\n",
            "\n",
            "Total Training Params:                                                  27.96 K \n",
            "fwd MACs:                                                               297.256 MMACs\n",
            "fwd FLOPs:                                                              594.799 MFLOPS\n",
            "fwd+bwd MACs:                                                           891.768 MMACs\n",
            "fwd+bwd FLOPs:                                                          1.7844 GFLOPS\n",
            "---------------------------------------------------------------------------------------------------\n",
            "Subnet FLOPs:594.799 MFLOPS   MACs:297.256 MMACs   Params:27.964 K \n",
            "\n",
            "acc before fine-tuning: 0.1011\n",
            "acc after fine-tuning: 0.1759\n",
            "(k, d, w): (5, 3, 2)\n",
            "\n",
            "------------------------------------- Calculate Flops Results -------------------------------------\n",
            "Notations:\n",
            "number of parameters (Params), number of multiply-accumulate operations(MACs),\n",
            "number of floating-point operations (FLOPs), floating-point operations per second (FLOPS),\n",
            "fwd FLOPs (model forward propagation FLOPs), bwd FLOPs (model backward propagation FLOPs),\n",
            "default model backpropagation takes 2.00 times as much computation as forward propagation.\n",
            "\n",
            "Total Training Params:                                                  27.96 K \n",
            "fwd MACs:                                                               286.949 MMACs\n",
            "fwd FLOPs:                                                              574.178 MFLOPS\n",
            "fwd+bwd MACs:                                                           860.846 MMACs\n",
            "fwd+bwd FLOPs:                                                          1.7225 GFLOPS\n",
            "---------------------------------------------------------------------------------------------------\n",
            "Subnet FLOPs:574.178 MFLOPS   MACs:286.949 MMACs   Params:27.964 K \n",
            "\n",
            "acc before fine-tuning: 0.0947\n",
            "acc after fine-tuning: 0.1005\n",
            "(k, d, w): (5, 3, 4)\n",
            "\n",
            "------------------------------------- Calculate Flops Results -------------------------------------\n",
            "Notations:\n",
            "number of parameters (Params), number of multiply-accumulate operations(MACs),\n",
            "number of floating-point operations (FLOPs), floating-point operations per second (FLOPS),\n",
            "fwd FLOPs (model forward propagation FLOPs), bwd FLOPs (model backward propagation FLOPs),\n",
            "default model backpropagation takes 2.00 times as much computation as forward propagation.\n",
            "\n",
            "Total Training Params:                                                  27.96 K \n",
            "fwd MACs:                                                               391.431 MMACs\n",
            "fwd FLOPs:                                                              783.216 MFLOPS\n",
            "fwd+bwd MACs:                                                           1.1743 GMACs\n",
            "fwd+bwd FLOPs:                                                          2.3496 GFLOPS\n",
            "---------------------------------------------------------------------------------------------------\n",
            "Subnet FLOPs:783.216 MFLOPS   MACs:391.431 MMACs   Params:27.964 K \n",
            "\n",
            "acc before fine-tuning: 0.1006\n",
            "acc after fine-tuning: 0.1021\n",
            "(k, d, w): (7, 2, 2)\n",
            "\n",
            "------------------------------------- Calculate Flops Results -------------------------------------\n",
            "Notations:\n",
            "number of parameters (Params), number of multiply-accumulate operations(MACs),\n",
            "number of floating-point operations (FLOPs), floating-point operations per second (FLOPS),\n",
            "fwd FLOPs (model forward propagation FLOPs), bwd FLOPs (model backward propagation FLOPs),\n",
            "default model backpropagation takes 2.00 times as much computation as forward propagation.\n",
            "\n",
            "Total Training Params:                                                  27.96 K \n",
            "fwd MACs:                                                               281.906 MMACs\n",
            "fwd FLOPs:                                                              564.086 MFLOPS\n",
            "fwd+bwd MACs:                                                           845.719 MMACs\n",
            "fwd+bwd FLOPs:                                                          1.6923 GFLOPS\n",
            "---------------------------------------------------------------------------------------------------\n",
            "Subnet FLOPs:564.086 MFLOPS   MACs:281.906 MMACs   Params:27.964 K \n",
            "\n",
            "acc before fine-tuning: 0.1058\n",
            "acc after fine-tuning: 0.1736\n",
            "(k, d, w): (7, 2, 4)\n",
            "\n",
            "------------------------------------- Calculate Flops Results -------------------------------------\n",
            "Notations:\n",
            "number of parameters (Params), number of multiply-accumulate operations(MACs),\n",
            "number of floating-point operations (FLOPs), floating-point operations per second (FLOPS),\n",
            "fwd FLOPs (model forward propagation FLOPs), bwd FLOPs (model backward propagation FLOPs),\n",
            "default model backpropagation takes 2.00 times as much computation as forward propagation.\n",
            "\n",
            "Total Training Params:                                                  27.96 K \n",
            "fwd MACs:                                                               297.748 MMACs\n",
            "fwd FLOPs:                                                              595.782 MFLOPS\n",
            "fwd+bwd MACs:                                                           893.242 MMACs\n",
            "fwd+bwd FLOPs:                                                          1.7873 GFLOPS\n",
            "---------------------------------------------------------------------------------------------------\n",
            "Subnet FLOPs:595.782 MFLOPS   MACs:297.748 MMACs   Params:27.964 K \n",
            "\n",
            "acc before fine-tuning: 0.1213\n",
            "acc after fine-tuning: 0.1666\n",
            "(k, d, w): (7, 3, 2)\n",
            "\n",
            "------------------------------------- Calculate Flops Results -------------------------------------\n",
            "Notations:\n",
            "number of parameters (Params), number of multiply-accumulate operations(MACs),\n",
            "number of floating-point operations (FLOPs), floating-point operations per second (FLOPS),\n",
            "fwd FLOPs (model forward propagation FLOPs), bwd FLOPs (model backward propagation FLOPs),\n",
            "default model backpropagation takes 2.00 times as much computation as forward propagation.\n",
            "\n",
            "Total Training Params:                                                  27.96 K \n",
            "fwd MACs:                                                               287.293 MMACs\n",
            "fwd FLOPs:                                                              574.867 MFLOPS\n",
            "fwd+bwd MACs:                                                           861.878 MMACs\n",
            "fwd+bwd FLOPs:                                                          1.7246 GFLOPS\n",
            "---------------------------------------------------------------------------------------------------\n",
            "Subnet FLOPs:574.867 MFLOPS   MACs:287.293 MMACs   Params:27.964 K \n",
            "\n",
            "acc before fine-tuning: 0.098\n",
            "acc after fine-tuning: 0.1\n",
            "(k, d, w): (7, 3, 4)\n",
            "\n",
            "------------------------------------- Calculate Flops Results -------------------------------------\n",
            "Notations:\n",
            "number of parameters (Params), number of multiply-accumulate operations(MACs),\n",
            "number of floating-point operations (FLOPs), floating-point operations per second (FLOPS),\n",
            "fwd FLOPs (model forward propagation FLOPs), bwd FLOPs (model backward propagation FLOPs),\n",
            "default model backpropagation takes 2.00 times as much computation as forward propagation.\n",
            "\n",
            "Total Training Params:                                                  27.96 K \n",
            "fwd MACs:                                                               393.496 MMACs\n",
            "fwd FLOPs:                                                              787.344 MFLOPS\n",
            "fwd+bwd MACs:                                                           1.1805 GMACs\n",
            "fwd+bwd FLOPs:                                                          2.362 GFLOPS\n",
            "---------------------------------------------------------------------------------------------------\n",
            "Subnet FLOPs:787.344 MFLOPS   MACs:393.496 MMACs   Params:27.964 K \n",
            "\n",
            "acc before fine-tuning: 0.1126\n",
            "acc after fine-tuning: 0.1015\n"
          ]
        }
      ],
      "source": [
        "fine_tune_epochs = 25\n",
        "configs = iterate_config_space(supernet.num_units, config_space)\n",
        "input_shape = (1, 3, 32, 32)\n",
        "for config in configs:\n",
        "  print(\"(k, d, w):\", (config[0][0][\"k\"], len(config[0]), config[0][0][\"w\"]))\n",
        "  subnet = ProgressiveShrinking(supernet, config)\n",
        "  subnet.to(device)\n",
        "  flops, macs, params = calculate_flops(model= supernet,\n",
        "                                      input_shape=input_shape,\n",
        "                                      output_as_string=True,\n",
        "                                      print_detailed=False,\n",
        "                                      output_precision=4)\n",
        "  print(\"Subnet FLOPs:%s   MACs:%s   Params:%s \\n\" %(flops, macs, params))\n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "  acc = evaluate(subnet, test_loader, device)\n",
        "  print(\"acc before fine-tuning:\", acc)\n",
        "  ft_optimizer = torch.optim.SGD(subnet.parameters(), lr=2e-5, momentum=0.9, weight_decay=3e-5)\n",
        "  ft_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(ft_optimizer, T_max=fine_tune_epochs)\n",
        "  for epoch in range(1, fine_tune_epochs + 1):\n",
        "    loss = train_one_epoch(subnet, train_loader, criterion, ft_optimizer, device)\n",
        "    ft_scheduler.step()\n",
        "  acc = evaluate(subnet, test_loader, device)\n",
        "  print(\"acc after fine-tuning:\", acc)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": [],
      "authorship_tag": "ABX9TyPmnG5s+/O33SIYLkDfNdCu",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}